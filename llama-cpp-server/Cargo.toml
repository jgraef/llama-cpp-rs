[package]
name = "llama-cpp-server"
version = "0.1.0"
edition = "2021"
authors = ["Janosch Gr√§f <janosch.graef@gmail.com>"]
description = "llama.cpp API server written in Rust"
repository = "https://github.com/jgraef/llama-cpp-rs"
# todo: add this once it's on docs.rs
# documentation = ""
keywords = ["llm", "ai"]
categories = ["command-line-utilities", "science", "text-processing"]
readme = "../README.md"
license = "MIT"

[dependencies]
tracing = "0.1"
tracing-subscriber = "0.3"
dotenvy = "0.15"
color-eyre = "0.6"
tokio = { version = "1.33", features = ["rt-multi-thread", "macros"] }
structopt = "0.3"
futures = "0.3"
axum = { version = "0.7", features = ["tokio"] }
tower = "0.4"
utoipa = { version = "4.2", features = ["axum_extras"] }
utoipa-swagger-ui = { version = "6.0", features = ["axum"] }
serde = { version = "1.0", features = ["derive"] }
thiserror = "1.0"
async-stream = "0.3"

[dependencies.llama-cpp]
version = "0.1.0"
path = "../llama-cpp"
features = ["runtime-tokio"]
